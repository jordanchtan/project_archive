{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2 No Likes.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOPvUzvm3+kwq4WaUxF2ssB"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"c8B9sNNcwyBq","colab_type":"code","colab":{}},"source":["# pip install sklearn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_wbMW_7mmNu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"76c4e9f9-0c70-4234-9366-b7c68cc8fca6","executionInfo":{"status":"ok","timestamp":1591712400507,"user_tz":-480,"elapsed":3026,"user":{"displayName":"Jordan Tan","photoUrl":"","userId":"08837459994650607663"}}},"source":["import keras.backend as K\n","import tensorflow as tf\n","\n","from scipy.spatial.distance import jensenshannon\n","from numpy import asarray\n","\n","kl_div = tf.keras.losses.KLDivergence()\n"," \n","# calculate the js divergence\n","def js_divergence(p, q):\n","\tm = 0.5 * (p + q)\n","\treturn 0.5 * kl_div(p, m) + 0.5 * kl_div(q, m)\n","\n","def js_distance(y_true, y_pred):\n","  return K.sqrt(js_divergence(y_true, y_pred))\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"yzN2-yCYkQnq","colab_type":"text"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"1-VbNYCEjJvo","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","\n","def load_data():\n","  # load your data using this function\n","  # url = 'https://raw.githubusercontent.com/jordanchtan/EvaluationData/master/ReactDataCounts/2_No_Likes.csv'\n","  url = 'https://raw.githubusercontent.com/jordanchtan/EvaluationData/master/ReactDataCountsPre/2_No_Likes.csv'\n","  df = pd.read_csv(url, encoding='utf16')\n","  n = 100\n","  df = df.head(int(len(df)*(n/100)))\n","\n","  data = df['name']\n","  labels = df.select_dtypes(include=[np.number])\n","\n","  data = data.values\n","  labels = labels.values\n","\n","  return data, labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HRiG3Ed4kW02","colab_type":"text"},"source":["# Create Model"]},{"cell_type":"code","metadata":{"id":"D6Z_2bSpkcrF","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","\n","metrics = ['mean_squared_error', 'mean_absolute_error', 'categorical_crossentropy',js_distance]\n","\n","def create_model(input_dim):\n","  model = Sequential()\n","  model.add(Dense(units=500, activation='relu', input_dim=input_dim))\n","  model.add(Dense(units=5, activation='relu'))\n","  \n","  # model.compile(loss='kullback_leibler_divergence', optimizer='adam', metrics=metrics)\n","  # model.compile(loss=js_divergence, optimizer='adam', metrics=metrics)\n","  model.compile(loss='mean_squared_error', optimizer='adam', metrics=metrics)\n","  # model.summary()\n","  print(model.summary())\n","  from keras.utils.vis_utils import plot_model\n","  plot_model(model, to_file='2_No_Likes.png', show_shapes=True, show_layer_names=True)\n","\n","  return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lAGxM4t4kdFc","colab_type":"text"},"source":["# Train and Evaluate Model"]},{"cell_type":"code","metadata":{"id":"_RoJspSWkhhL","colab_type":"code","outputId":"1180cf45-d10f-4d48-875f-4f02665f9350","executionInfo":{"status":"ok","timestamp":1591712401137,"user_tz":-480,"elapsed":3637,"user":{"displayName":"Jordan Tan","photoUrl":"","userId":"08837459994650607663"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["import nltk\n","nltk.download('stopwords')\n","from sklearn.feature_extraction.text import CountVectorizer\n","from nltk.corpus import stopwords\n","from sklearn.model_selection import train_test_split\n","import sklearn\n","\n","\n","def train_and_evaluate_model(model, data_train, labels_train, data_test, labels_test):\n","  print(\"Training:\")\n","  data_train, data_val, labels_train, labels_val = train_test_split(data_train, labels_train, test_size=0.2, shuffle=True)\n","  # data_test, data_val, labels_test, labels_val = train_test_split(data_test, labels_test, test_size=0.5, shuffle=True)\n","\n","  model.fit(data_train, labels_train, \n","        epochs=2, batch_size=128, verbose=1, shuffle=True,\n","        validation_data=(data_val, labels_val))\n","  \n","  print(\"Evaluating:\")\n","  scores = model.evaluate(data_test, labels_test, verbose=1)\n","  print(\"Final scores for fold:\")\n","  print(model.metrics_names, scores) \n","  y_pred = model.predict(data_test)\n","  print(y_pred.shape)\n","  print('col 0', sklearn.metrics.mean_squared_error(labels_test[:,0], y_pred[:,0]))\n","  print('col 1', sklearn.metrics.mean_squared_error(labels_test[:,1], y_pred[:,1]))\n","  print('col 2', sklearn.metrics.mean_squared_error(labels_test[:,2], y_pred[:,2]))\n","  print('col 3', sklearn.metrics.mean_squared_error(labels_test[:,3], y_pred[:,3]))\n","  print('col 4', sklearn.metrics.mean_squared_error(labels_test[:,4], y_pred[:,4]))\n","  print('col 5', sklearn.metrics.mean_squared_error(labels_test[:,5], y_pred[:,5]))\n","  return scores"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2G1rqoZ-lmIY","colab_type":"text"},"source":["# Run Evaluation"]},{"cell_type":"code","metadata":{"id":"pVL64lSAZ1KW","colab_type":"code","outputId":"f1935446-4ae2-41a3-f75d-5710806639cb","executionInfo":{"status":"ok","timestamp":1591712403409,"user_tz":-480,"elapsed":5898,"user":{"displayName":"Jordan Tan","photoUrl":"","userId":"08837459994650607663"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data, labels = load_data()\n","print(len(data))\n","useHoldout = False\n","\n","min_reacts = 1\n","if (len(data) > 10000):\n","  useHoldout = True"],"execution_count":6,"outputs":[{"output_type":"stream","text":["155696\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I8wEi4vnmlB6","colab_type":"code","outputId":"8f2374ca-bb3a-4dcb-a784-9d0cec42c50a","executionInfo":{"status":"ok","timestamp":1591712403411,"user_tz":-480,"elapsed":5892,"user":{"displayName":"Jordan Tan","photoUrl":"","userId":"08837459994650607663"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["print(labels)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[[  88    5    6   45    0]\n"," [ 109  186    1  499   44]\n"," [6634 5509 2854   19   10]\n"," ...\n"," [   2    0    1    0    0]\n"," [   0   11    1    0    0]\n"," [ 457 1109 3816   11   46]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A-ZN6gj0qTR4","colab_type":"text"},"source":["K-Fold"]},{"cell_type":"code","metadata":{"id":"jb4ElLALlpDB","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import KFold\n","from sklearn.preprocessing import normalize\n","\n","\n","if not useHoldout:\n","  print(\"KFOLD\")  \n","  n_folds = 5\n","  kf = KFold(n_folds, shuffle=True)\n","  i = 0\n","\n","  # Define per-fold score containers\n","  scores_per_fold = []\n","\n","  for train_index, test_index in kf.split(data):\n","    print(\"Running Fold\", i+1, \"/\", n_folds)\n","    data_train, data_test = data[train_index], data[test_index]\n","    labels_train, labels_test = labels[train_index], labels[test_index]\n","\n","    labels_train_sums = labels_train.sum(axis = 1)\n","    has_min_reacts = labels_train_sums >= min_reacts\n","    data_train = data_train[has_min_reacts]\n","    labels_train = labels_train[has_min_reacts]\n","\n","    labels_train = labels_train/labels_train.sum(axis=1, keepdims=True)\n","    labels_test = labels_test/labels_test.sum(axis=1, keepdims=True)\n","\n","\n","    #process\n","    vectorizer = CountVectorizer(max_features=20000, binary=False)\n","    # vectorizer = CountVectorizer(binary=True, stop_words=stopwords.words('english'), \n","    #                             lowercase=True, min_df=3, max_df=0.9, max_features=5000)\n","    data_train = vectorizer.fit_transform(data_train.astype('U'))\n","\n","    data_test = vectorizer.transform(data_test.astype('U'))\n","    # end\n","    \n","    model = None # Clearing the NN.\n","    model = create_model(len(vectorizer.get_feature_names()))\n","\n","    scores = train_and_evaluate_model(model, data_train, labels_train, data_test, labels_test)\n","    scores_per_fold.append(scores)\n","\n","    i += 1\n","\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3fFIvAn4WA02","colab_type":"code","colab":{}},"source":["if not useHoldout:\n","\n","  print('Average scores across all folds:')\n","  for metric_index, metric_name in enumerate(metrics):\n","    metric_total = 0\n","    for scores in scores_per_fold:\n","      metric_total += scores[metric_index + 1]\n","    print(metric_name, metric_total/n_folds )\n","  print(scores_per_fold)\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8BF47pGqVpa","colab_type":"text"},"source":["Holdout"]},{"cell_type":"code","metadata":{"id":"UTR6zCWejJpJ","colab_type":"code","outputId":"1fff20ab-6eb5-4618-9b04-c03882fa5aed","executionInfo":{"status":"ok","timestamp":1591712405964,"user_tz":-480,"elapsed":8434,"user":{"displayName":"Jordan Tan","photoUrl":"","userId":"08837459994650607663"}},"colab":{"base_uri":"https://localhost:8080/","height":252}},"source":["from sklearn.model_selection import train_test_split\n","\n","if useHoldout:\n","  print(\"HOLDOUT\")\n","\n","  data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.2, shuffle=True)\n","\n","  labels_train_sums = labels_train.sum(axis = 1)\n","  has_min_reacts = labels_train_sums >= min_reacts\n","  data_train = data_train[has_min_reacts]\n","  labels_train = labels_train[has_min_reacts]\n","  \n","  labels_train = labels_train/labels_train.sum(axis=1, keepdims=True)\n","  labels_test = labels_test/labels_test.sum(axis=1, keepdims=True)\n","\n","  #process\n","  vectorizer = CountVectorizer(max_features=5000, binary=True)\n","  # vectorizer = CountVectorizer(max_features=5000, binary=True)\n","  # vectorizer = CountVectorizer(binary=True, stop_words=stopwords.words('english'), \n","  #                             lowercase=True, min_df=3, max_df=0.9, max_features=5000)\n","  data_train = vectorizer.fit_transform(data_train.astype('U'))\n","\n","  data_test = vectorizer.transform(data_test.astype('U'))\n","  # end\n","\n","  model = None # Clearing the NN.\n","  model = create_model(len(vectorizer.get_feature_names()))\n","\n","  # scores = train_and_evaluate_model(model, data_train, labels_train, data_test, labels_test)\n","  # print(model.metrics_names, scores) \n","# ['loss', 'mean_squared_error', 'mean_absolute_error', 'js_distance'] [0.051870411047777766, 0.0518704317510128, 0.15690724551677704, 0.38542553782463074]\n","# softmax cce\n","# ['loss', 'mean_squared_error', 'mean_absolute_error', 'categorical_crossentropy', 'js_distance'] [1.3029636577680928, 0.0507490374147892, 0.1581949144601822, 1.3029628992080688, 0.38368284702301025]\n","# col 0 0.08069338785648082\n","# col 1 0.04315388244847084\n","# col 2 0.045754739576135\n","# col 3 0.04100759413744935\n","# col 4 0.04474218285218102\n","# ---------------------------"],"execution_count":10,"outputs":[{"output_type":"stream","text":["HOLDOUT\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 500)               2500500   \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 5)                 2505      \n","=================================================================\n","Total params: 2,503,005\n","Trainable params: 2,503,005\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]}]}